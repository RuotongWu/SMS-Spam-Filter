{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from data_helper.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import import_ipynb\n",
    "import os\n",
    "import pandas as pd\n",
    "from data_helper import data_loader\n",
    "import tensorflow as tf\n",
    "import time\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 file_name,\n",
    "                 ratio = 0.9,\n",
    "                 shuffle = False,\n",
    "                 encoding = True,\n",
    "                 unites = 128,\n",
    "                 BATCH_SIZE = 64,\n",
    "                 optimizer = tf.train.AdamOptimizer(),\n",
    "                 loss_object = tf.keras.losses.BinaryCrossentropy()):\n",
    "        self.__load_processed_data(file_name,split_ratio = ratio,shuffle=shuffle,encoding = encoding)\n",
    "        self.__units = unites\n",
    "        self.__BATCH_SIZE = BATCH_SIZE\n",
    "        self.__encoder = Encoder(self.__vocab_size, self.__units, self.__BATCH_SIZE)\n",
    "        #sample_hidden = encoder.initialize_hidden_state()\n",
    "        #sample_output, sample_hidden = encoder(train_message[:64], sample_hidden)\n",
    "        self.__optimizer = optimizer\n",
    "        self.__loss_object = loss_object\n",
    "        self.__decoder = Decoder(1, self.__units, self.__BATCH_SIZE)\n",
    "        \n",
    "        self.__checkpoint_dir = os.getcwd()+r'/checkpoint/training_checkpoints'+\"//\"+file_name\n",
    "        self.__checkpoint_prefix = os.path.join(self.__checkpoint_dir, \"ckpt\")\n",
    "        self.__checkpoint = tf.train.Checkpoint(optimizer=self.__optimizer,\n",
    "                                                encoder=self.__encoder,\n",
    "                                                decoder=self.__decoder)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __load_processed_data(self, file_name,split_ratio = 0.9, shuffle = False, encoding = True):\n",
    "        current_path = os.getcwd()\n",
    "        pickle_data_folder = current_path+ r\"/data/processed\"\n",
    "        file_path = pickle_data_folder + \"//\" + file_name\n",
    "        with open(file_path,'rb') as f:\n",
    "            self.__data = pickle.load(f)\n",
    "        self.__dic = self.__data.word_dic\n",
    "        self.__vocab_size = len(self.__dic)\n",
    "        self.__train_message, self.__train_tag, self.__test_message, self.__test_tag = self.__data.data_split()\n",
    "        self.__train_message = tf.convert_to_tensor(self.__train_message,dtype=np.float32)\n",
    "        self.__train_tag = self.__train_tag.reshape(-1,1)\n",
    "        self.__train_tag = tf.convert_to_tensor(self.__train_tag,dtype=np.float32)\n",
    "\n",
    "        self.__test_message = tf.convert_to_tensor(self.__test_message,dtype=np.float32)\n",
    "        #self.__test_tag=self.__test_tag.reshape(-1,1)\n",
    "        #self.__test_tag = tf.convert_to_tensor(self.__test_tag,dtype=np.float32)\n",
    "        \n",
    "    def __loss_function(self, real, pred):\n",
    "        mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "        loss_ = self.__loss_object(real, pred)\n",
    "\n",
    "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "        loss_ *= mask\n",
    "\n",
    "        return tf.reduce_mean(loss_)\n",
    "    \n",
    "    def __batch_generator(self,message, target,batch_size):\n",
    "        times = len(message)//batch_size\n",
    "        remain = batch_size - len(message)%batch_size\n",
    "    \n",
    "        for n in range(times):\n",
    "            yield message[n*batch_size: (n+1)*batch_size], target[n*batch_size: (n+1)*batch_size]\n",
    "    \n",
    "    def __train_steps(self, inp, targ, enc_hidden):\n",
    "        loss = 0\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = self.__encoder(inp, enc_hidden)\n",
    "\n",
    "            dec_hidden = enc_hidden\n",
    "\n",
    "            dec_input = tf.expand_dims([1.] * self.__BATCH_SIZE, 1)\n",
    "            for t in range(targ.shape[1]):\n",
    "                predictions, dec_hidden, _ = self.__decoder(dec_input, dec_hidden, enc_output)\n",
    "                loss += self.__loss_function(targ, predictions)\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "        variables = self.__encoder.trainable_variables + self.__decoder.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "\n",
    "        self.__optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        return batch_loss\n",
    "    \n",
    "    def train(self, EPOCHS = 10):\n",
    "        EPOCHS = EPOCHS\n",
    "        for epoch in range(EPOCHS):\n",
    "            start = time.time()\n",
    "            enc_hidden = self.__encoder.initialize_hidden_state()\n",
    "            total_loss = 0\n",
    "    \n",
    "            for (batch, (inp, targ)) in enumerate(self.__batch_generator(self.__train_message, self.__train_tag, self.__BATCH_SIZE)):\n",
    "                batch_loss = self.__train_steps(inp, targ, enc_hidden)\n",
    "                total_loss += batch_loss\n",
    "                #'''\n",
    "                if batch % 10 == 0:\n",
    "                    print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                                 batch,\n",
    "                                                                 batch_loss.numpy()))\n",
    "                #'''\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                self.__checkpoint.save(file_prefix = self.__checkpoint_prefix)\n",
    "            print('Epoch {} Loss {:.4f}'.format(epoch + 1,total_loss / self.__BATCH_SIZE))\n",
    "            print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "            \n",
    "        \n",
    "    def __evaluate(self,sentence):\n",
    "        inputs = tf.convert_to_tensor([sentence],dtype=np.float32)\n",
    "        result = None\n",
    "        hidden = [tf.zeros((1, self.__units))]\n",
    "        enc_out, enc_hidden = self.__encoder(inputs, hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([1.], 0)\n",
    "        predictions, dec_hidden, attention_weights = self.__decoder(dec_input,\n",
    "                                                                    dec_hidden,\n",
    "                                                                    enc_out)\n",
    "        result = 1 if float(predictions)>0.5 else 0\n",
    "        return result\n",
    "    \n",
    "    def predict(self):\n",
    "        self.__checkpoint.restore(tf.train.latest_checkpoint(self.__checkpoint_dir))\n",
    "        results = []\n",
    "        for n in range(len(self.__test_message)):\n",
    "            result= self.__evaluate(self.__test_message[n])\n",
    "            results.append(result)\n",
    "            '''\n",
    "            if n%20 == 0:\n",
    "                print(\"processed {} sentences\".format(n))\n",
    "            '''\n",
    "                \n",
    "        count_wrong = 0\n",
    "        for p,r in zip(results,self.__test_tag):\n",
    "            if p != r:\n",
    "                count_wrong += 1\n",
    "                \n",
    "        return results,1-count_wrong/len(results)\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, enc_units, batch_sz):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units, \n",
    "                                       return_sequences = True,\n",
    "                                       return_state = True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "    def call(self,x,hidden):\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size,dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size,activation='sigmoid')\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = tf.expand_dims(x,1)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========200d_lower_processed_data.pkl=========\n",
      "Training:\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1 Batch 0 Loss 0.1302\n",
      "Epoch 1 Batch 10 Loss 0.0377\n",
      "Epoch 1 Batch 20 Loss 0.0186\n",
      "Epoch 1 Batch 30 Loss 0.0332\n",
      "Epoch 1 Batch 40 Loss 0.0152\n",
      "Epoch 1 Batch 50 Loss 0.0012\n",
      "Epoch 1 Batch 60 Loss 0.0342\n",
      "Epoch 1 Batch 70 Loss 0.0182\n",
      "Epoch 1 Loss 0.0424\n",
      "Time taken for 1 epoch 88.74951124191284 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.0173\n",
      "Epoch 2 Batch 10 Loss 0.0151\n",
      "Epoch 2 Batch 20 Loss 0.0051\n",
      "Epoch 2 Batch 30 Loss 0.0108\n",
      "Epoch 2 Batch 40 Loss 0.0036\n",
      "Epoch 2 Batch 50 Loss 0.0005\n",
      "Epoch 2 Batch 60 Loss 0.0211\n",
      "Epoch 2 Batch 70 Loss 0.0168\n",
      "Epoch 2 Loss 0.0106\n",
      "Time taken for 1 epoch 88.43227648735046 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0095\n",
      "Epoch 3 Batch 10 Loss 0.0101\n",
      "Epoch 3 Batch 20 Loss 0.0046\n",
      "Epoch 3 Batch 30 Loss 0.0039\n",
      "Epoch 3 Batch 40 Loss 0.0012\n",
      "Epoch 3 Batch 50 Loss 0.0002\n",
      "Epoch 3 Batch 60 Loss 0.0059\n",
      "Epoch 3 Batch 70 Loss 0.0172\n",
      "Epoch 3 Loss 0.0063\n",
      "Time taken for 1 epoch 86.40905952453613 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0084\n",
      "Epoch 4 Batch 10 Loss 0.0062\n",
      "Epoch 4 Batch 20 Loss 0.0019\n",
      "Epoch 4 Batch 30 Loss 0.0032\n",
      "Epoch 4 Batch 40 Loss 0.0004\n",
      "Epoch 4 Batch 50 Loss 0.0002\n",
      "Epoch 4 Batch 60 Loss 0.0032\n",
      "Epoch 4 Batch 70 Loss 0.0103\n",
      "Epoch 4 Loss 0.0043\n",
      "Time taken for 1 epoch 87.4902606010437 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0006\n",
      "Epoch 5 Batch 10 Loss 0.0093\n",
      "Epoch 5 Batch 20 Loss 0.0015\n",
      "Epoch 5 Batch 30 Loss 0.0005\n",
      "Epoch 5 Batch 40 Loss 0.0002\n",
      "Epoch 5 Batch 50 Loss 0.0023\n",
      "Epoch 5 Batch 60 Loss 0.0077\n",
      "Epoch 5 Batch 70 Loss 0.0034\n",
      "Epoch 5 Loss 0.0041\n",
      "Time taken for 1 epoch 88.83303236961365 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0007\n",
      "Epoch 6 Batch 10 Loss 0.0042\n",
      "Epoch 6 Batch 20 Loss 0.0019\n",
      "Epoch 6 Batch 30 Loss 0.0005\n",
      "Epoch 6 Batch 40 Loss 0.0002\n",
      "Epoch 6 Batch 50 Loss 0.0001\n",
      "Epoch 6 Batch 60 Loss 0.0010\n",
      "Epoch 6 Batch 70 Loss 0.0008\n",
      "Epoch 6 Loss 0.0028\n",
      "Time taken for 1 epoch 88.34467816352844 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0018\n",
      "Epoch 7 Batch 10 Loss 0.0002\n",
      "Epoch 7 Batch 20 Loss 0.0010\n",
      "Epoch 7 Batch 30 Loss 0.0002\n",
      "Epoch 7 Batch 40 Loss 0.0002\n",
      "Epoch 7 Batch 50 Loss 0.0000\n",
      "Epoch 7 Batch 60 Loss 0.0140\n",
      "Epoch 7 Batch 70 Loss 0.0017\n",
      "Epoch 7 Loss 0.0020\n",
      "Time taken for 1 epoch 86.98803043365479 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0002\n",
      "Epoch 8 Batch 10 Loss 0.0004\n",
      "Epoch 8 Batch 20 Loss 0.0006\n",
      "Epoch 8 Batch 30 Loss 0.0008\n",
      "Epoch 8 Batch 40 Loss 0.0000\n",
      "Epoch 8 Batch 50 Loss 0.0001\n",
      "Epoch 8 Batch 60 Loss 0.0001\n",
      "Epoch 8 Batch 70 Loss 0.0005\n",
      "Epoch 8 Loss 0.0010\n",
      "Time taken for 1 epoch 86.9000723361969 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0001\n",
      "Epoch 9 Batch 10 Loss 0.0002\n",
      "Epoch 9 Batch 20 Loss 0.0002\n",
      "Epoch 9 Batch 30 Loss 0.0000\n",
      "Epoch 9 Batch 40 Loss 0.0000\n",
      "Epoch 9 Batch 50 Loss 0.0000\n",
      "Epoch 9 Batch 60 Loss 0.0001\n",
      "Epoch 9 Batch 70 Loss 0.0004\n",
      "Epoch 9 Loss 0.0004\n",
      "Time taken for 1 epoch 88.57025504112244 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0000\n",
      "Epoch 10 Batch 10 Loss 0.0001\n",
      "Epoch 10 Batch 20 Loss 0.0002\n",
      "Epoch 10 Batch 30 Loss 0.0000\n",
      "Epoch 10 Batch 40 Loss 0.0000\n",
      "Epoch 10 Batch 50 Loss 0.0000\n",
      "Epoch 10 Batch 60 Loss 0.0000\n",
      "Epoch 10 Batch 70 Loss 0.0004\n",
      "Epoch 10 Loss 0.0003\n",
      "Time taken for 1 epoch 87.64536499977112 sec\n",
      "\n",
      "Evaluation:\n",
      "accuracy:0.989247311827957\n",
      "\n",
      "=========200d_processed_data.pkl=========\n",
      "Training:\n",
      "Epoch 1 Batch 0 Loss 0.1346\n",
      "Epoch 1 Batch 10 Loss 0.0346\n",
      "Epoch 1 Batch 20 Loss 0.0078\n",
      "Epoch 1 Batch 30 Loss 0.0134\n",
      "Epoch 1 Batch 40 Loss 0.0047\n",
      "Epoch 1 Batch 50 Loss 0.0016\n",
      "Epoch 1 Batch 60 Loss 0.0246\n",
      "Epoch 1 Batch 70 Loss 0.0193\n",
      "Epoch 1 Loss 0.0357\n",
      "Time taken for 1 epoch 88.26135182380676 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.0302\n",
      "Epoch 2 Batch 10 Loss 0.0196\n",
      "Epoch 2 Batch 20 Loss 0.0025\n",
      "Epoch 2 Batch 30 Loss 0.0030\n",
      "Epoch 2 Batch 40 Loss 0.0024\n",
      "Epoch 2 Batch 50 Loss 0.0014\n",
      "Epoch 2 Batch 60 Loss 0.0082\n",
      "Epoch 2 Batch 70 Loss 0.0210\n",
      "Epoch 2 Loss 0.0104\n",
      "Time taken for 1 epoch 89.88601279258728 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0108\n",
      "Epoch 3 Batch 10 Loss 0.0191\n",
      "Epoch 3 Batch 20 Loss 0.0045\n",
      "Epoch 3 Batch 30 Loss 0.0008\n",
      "Epoch 3 Batch 40 Loss 0.0008\n",
      "Epoch 3 Batch 50 Loss 0.0007\n",
      "Epoch 3 Batch 60 Loss 0.0028\n",
      "Epoch 3 Batch 70 Loss 0.0164\n",
      "Epoch 3 Loss 0.0051\n",
      "Time taken for 1 epoch 89.1533133983612 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0009\n",
      "Epoch 4 Batch 10 Loss 0.0142\n",
      "Epoch 4 Batch 20 Loss 0.0014\n",
      "Epoch 4 Batch 30 Loss 0.0005\n",
      "Epoch 4 Batch 40 Loss 0.0005\n",
      "Epoch 4 Batch 50 Loss 0.0005\n",
      "Epoch 4 Batch 60 Loss 0.0009\n",
      "Epoch 4 Batch 70 Loss 0.0161\n",
      "Epoch 4 Loss 0.0030\n",
      "Time taken for 1 epoch 89.52353501319885 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0003\n",
      "Epoch 5 Batch 10 Loss 0.0095\n",
      "Epoch 5 Batch 20 Loss 0.0006\n",
      "Epoch 5 Batch 30 Loss 0.0003\n",
      "Epoch 5 Batch 40 Loss 0.0003\n",
      "Epoch 5 Batch 50 Loss 0.0003\n",
      "Epoch 5 Batch 60 Loss 0.0031\n",
      "Epoch 5 Batch 70 Loss 0.0155\n",
      "Epoch 5 Loss 0.0023\n",
      "Time taken for 1 epoch 88.84456539154053 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0001\n",
      "Epoch 6 Batch 10 Loss 0.0007\n",
      "Epoch 6 Batch 20 Loss 0.0003\n",
      "Epoch 6 Batch 30 Loss 0.0003\n",
      "Epoch 6 Batch 40 Loss 0.0004\n",
      "Epoch 6 Batch 50 Loss 0.0003\n",
      "Epoch 6 Batch 60 Loss 0.0014\n",
      "Epoch 6 Batch 70 Loss 0.0044\n",
      "Epoch 6 Loss 0.0015\n",
      "Time taken for 1 epoch 87.19784450531006 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0002\n",
      "Epoch 7 Batch 10 Loss 0.0002\n",
      "Epoch 7 Batch 20 Loss 0.0003\n",
      "Epoch 7 Batch 30 Loss 0.0003\n",
      "Epoch 7 Batch 40 Loss 0.0004\n",
      "Epoch 7 Batch 50 Loss 0.0003\n",
      "Epoch 7 Batch 60 Loss 0.0007\n",
      "Epoch 7 Batch 70 Loss 0.0015\n",
      "Epoch 7 Loss 0.0011\n",
      "Time taken for 1 epoch 89.01016855239868 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0001\n",
      "Epoch 8 Batch 10 Loss 0.0003\n",
      "Epoch 8 Batch 20 Loss 0.0000\n",
      "Epoch 8 Batch 30 Loss 0.0002\n",
      "Epoch 8 Batch 40 Loss 0.0004\n",
      "Epoch 8 Batch 50 Loss 0.0003\n",
      "Epoch 8 Batch 60 Loss 0.0008\n",
      "Epoch 8 Batch 70 Loss 0.0015\n",
      "Epoch 8 Loss 0.0010\n",
      "Time taken for 1 epoch 87.26763463020325 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0001\n",
      "Epoch 9 Batch 10 Loss 0.0000\n",
      "Epoch 9 Batch 20 Loss 0.0000\n",
      "Epoch 9 Batch 30 Loss 0.0002\n",
      "Epoch 9 Batch 40 Loss 0.0004\n",
      "Epoch 9 Batch 50 Loss 0.0003\n",
      "Epoch 9 Batch 60 Loss 0.0007\n",
      "Epoch 9 Batch 70 Loss 0.0016\n",
      "Epoch 9 Loss 0.0009\n",
      "Time taken for 1 epoch 88.47653198242188 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0001\n",
      "Epoch 10 Batch 10 Loss 0.0000\n",
      "Epoch 10 Batch 20 Loss 0.0000\n",
      "Epoch 10 Batch 30 Loss 0.0002\n",
      "Epoch 10 Batch 40 Loss 0.0004\n",
      "Epoch 10 Batch 50 Loss 0.0003\n",
      "Epoch 10 Batch 60 Loss 0.0007\n",
      "Epoch 10 Batch 70 Loss 0.0016\n",
      "Epoch 10 Loss 0.0009\n",
      "Time taken for 1 epoch 88.6254665851593 sec\n",
      "\n",
      "Evaluation:\n",
      "accuracy:0.9802867383512545\n",
      "\n",
      "=========25d_processed_data.pkl=========\n",
      "Training:\n",
      "Epoch 1 Batch 0 Loss 0.1339\n",
      "Epoch 1 Batch 10 Loss 0.0380\n",
      "Epoch 1 Batch 20 Loss 0.0122\n",
      "Epoch 1 Batch 30 Loss 0.0366\n",
      "Epoch 1 Batch 40 Loss 0.0452\n",
      "Epoch 1 Batch 50 Loss 0.0149\n",
      "Epoch 1 Batch 60 Loss 0.0422\n",
      "Epoch 1 Batch 70 Loss 0.0418\n",
      "Epoch 1 Loss 0.0571\n",
      "Time taken for 1 epoch 65.76672339439392 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.0478\n",
      "Epoch 2 Batch 10 Loss 0.0336\n",
      "Epoch 2 Batch 20 Loss 0.0085\n",
      "Epoch 2 Batch 30 Loss 0.0277\n",
      "Epoch 2 Batch 40 Loss 0.0114\n",
      "Epoch 2 Batch 50 Loss 0.0057\n",
      "Epoch 2 Batch 60 Loss 0.0365\n",
      "Epoch 2 Batch 70 Loss 0.0205\n",
      "Epoch 2 Loss 0.0297\n",
      "Time taken for 1 epoch 63.509825468063354 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0504\n",
      "Epoch 3 Batch 10 Loss 0.0166\n",
      "Epoch 3 Batch 20 Loss 0.0092\n",
      "Epoch 3 Batch 30 Loss 0.0144\n",
      "Epoch 3 Batch 40 Loss 0.0079\n",
      "Epoch 3 Batch 50 Loss 0.0023\n",
      "Epoch 3 Batch 60 Loss 0.0405\n",
      "Epoch 3 Batch 70 Loss 0.0141\n",
      "Epoch 3 Loss 0.0190\n",
      "Time taken for 1 epoch 66.17370390892029 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0124\n",
      "Epoch 4 Batch 10 Loss 0.0225\n",
      "Epoch 4 Batch 20 Loss 0.0047\n",
      "Epoch 4 Batch 30 Loss 0.0068\n",
      "Epoch 4 Batch 40 Loss 0.0043\n",
      "Epoch 4 Batch 50 Loss 0.0016\n",
      "Epoch 4 Batch 60 Loss 0.0365\n",
      "Epoch 4 Batch 70 Loss 0.0112\n",
      "Epoch 4 Loss 0.0170\n",
      "Time taken for 1 epoch 65.24041819572449 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0167\n",
      "Epoch 5 Batch 10 Loss 0.0108\n",
      "Epoch 5 Batch 20 Loss 0.0024\n",
      "Epoch 5 Batch 30 Loss 0.0059\n",
      "Epoch 5 Batch 40 Loss 0.0016\n",
      "Epoch 5 Batch 50 Loss 0.0013\n",
      "Epoch 5 Batch 60 Loss 0.0224\n",
      "Epoch 5 Batch 70 Loss 0.0084\n",
      "Epoch 5 Loss 0.0117\n",
      "Time taken for 1 epoch 64.79552173614502 sec\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 0 Loss 0.0150\n",
      "Epoch 6 Batch 10 Loss 0.0081\n",
      "Epoch 6 Batch 20 Loss 0.0031\n",
      "Epoch 6 Batch 30 Loss 0.0094\n",
      "Epoch 6 Batch 40 Loss 0.0013\n",
      "Epoch 6 Batch 50 Loss 0.0009\n",
      "Epoch 6 Batch 60 Loss 0.0127\n",
      "Epoch 6 Batch 70 Loss 0.0060\n",
      "Epoch 6 Loss 0.0098\n",
      "Time taken for 1 epoch 64.62760305404663 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0118\n",
      "Epoch 7 Batch 10 Loss 0.0046\n",
      "Epoch 7 Batch 20 Loss 0.0031\n",
      "Epoch 7 Batch 30 Loss 0.0026\n",
      "Epoch 7 Batch 40 Loss 0.0011\n",
      "Epoch 7 Batch 50 Loss 0.0020\n",
      "Epoch 7 Batch 60 Loss 0.0106\n",
      "Epoch 7 Batch 70 Loss 0.0032\n",
      "Epoch 7 Loss 0.0088\n",
      "Time taken for 1 epoch 64.62476539611816 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0122\n",
      "Epoch 8 Batch 10 Loss 0.0037\n",
      "Epoch 8 Batch 20 Loss 0.0011\n",
      "Epoch 8 Batch 30 Loss 0.0017\n",
      "Epoch 8 Batch 40 Loss 0.0019\n",
      "Epoch 8 Batch 50 Loss 0.0009\n",
      "Epoch 8 Batch 60 Loss 0.0075\n",
      "Epoch 8 Batch 70 Loss 0.0062\n",
      "Epoch 8 Loss 0.0070\n",
      "Time taken for 1 epoch 65.78391361236572 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0095\n",
      "Epoch 9 Batch 10 Loss 0.0018\n",
      "Epoch 9 Batch 20 Loss 0.0027\n",
      "Epoch 9 Batch 30 Loss 0.0015\n",
      "Epoch 9 Batch 40 Loss 0.0004\n",
      "Epoch 9 Batch 50 Loss 0.0026\n",
      "Epoch 9 Batch 60 Loss 0.0051\n",
      "Epoch 9 Batch 70 Loss 0.0020\n",
      "Epoch 9 Loss 0.0059\n",
      "Time taken for 1 epoch 65.2915506362915 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0052\n",
      "Epoch 10 Batch 10 Loss 0.0027\n",
      "Epoch 10 Batch 20 Loss 0.0030\n",
      "Epoch 10 Batch 30 Loss 0.0013\n",
      "Epoch 10 Batch 40 Loss 0.0003\n",
      "Epoch 10 Batch 50 Loss 0.0031\n",
      "Epoch 10 Batch 60 Loss 0.0103\n",
      "Epoch 10 Batch 70 Loss 0.0020\n",
      "Epoch 10 Loss 0.0067\n",
      "Time taken for 1 epoch 65.00995779037476 sec\n",
      "\n",
      "Evaluation:\n",
      "accuracy:0.9802867383512545\n",
      "\n",
      "=========25d_lower_processed_data.pkl=========\n",
      "Training:\n",
      "Epoch 1 Batch 0 Loss 0.1313\n",
      "Epoch 1 Batch 10 Loss 0.0355\n",
      "Epoch 1 Batch 20 Loss 0.0098\n",
      "Epoch 1 Batch 30 Loss 0.0183\n",
      "Epoch 1 Batch 40 Loss 0.0076\n",
      "Epoch 1 Batch 50 Loss 0.0019\n",
      "Epoch 1 Batch 60 Loss 0.0385\n",
      "Epoch 1 Batch 70 Loss 0.0160\n",
      "Epoch 1 Loss 0.0375\n",
      "Time taken for 1 epoch 64.33340835571289 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.0207\n",
      "Epoch 2 Batch 10 Loss 0.0122\n",
      "Epoch 2 Batch 20 Loss 0.0042\n",
      "Epoch 2 Batch 30 Loss 0.0074\n",
      "Epoch 2 Batch 40 Loss 0.0026\n",
      "Epoch 2 Batch 50 Loss 0.0007\n",
      "Epoch 2 Batch 60 Loss 0.0318\n",
      "Epoch 2 Batch 70 Loss 0.0134\n",
      "Epoch 2 Loss 0.0130\n",
      "Time taken for 1 epoch 65.68907046318054 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0319\n",
      "Epoch 3 Batch 10 Loss 0.0056\n",
      "Epoch 3 Batch 20 Loss 0.0022\n",
      "Epoch 3 Batch 30 Loss 0.0024\n",
      "Epoch 3 Batch 40 Loss 0.0034\n",
      "Epoch 3 Batch 50 Loss 0.0006\n",
      "Epoch 3 Batch 60 Loss 0.0157\n",
      "Epoch 3 Batch 70 Loss 0.0143\n",
      "Epoch 3 Loss 0.0081\n",
      "Time taken for 1 epoch 65.28934812545776 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0216\n",
      "Epoch 4 Batch 10 Loss 0.0015\n",
      "Epoch 4 Batch 20 Loss 0.0008\n",
      "Epoch 4 Batch 30 Loss 0.0011\n",
      "Epoch 4 Batch 40 Loss 0.0005\n",
      "Epoch 4 Batch 50 Loss 0.0003\n",
      "Epoch 4 Batch 60 Loss 0.0102\n",
      "Epoch 4 Batch 70 Loss 0.0136\n",
      "Epoch 4 Loss 0.0064\n",
      "Time taken for 1 epoch 65.71610069274902 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0068\n",
      "Epoch 5 Batch 10 Loss 0.0069\n",
      "Epoch 5 Batch 20 Loss 0.0013\n",
      "Epoch 5 Batch 30 Loss 0.0038\n",
      "Epoch 5 Batch 40 Loss 0.0007\n",
      "Epoch 5 Batch 50 Loss 0.0002\n",
      "Epoch 5 Batch 60 Loss 0.0051\n",
      "Epoch 5 Batch 70 Loss 0.0139\n",
      "Epoch 5 Loss 0.0051\n",
      "Time taken for 1 epoch 63.81626629829407 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0011\n",
      "Epoch 6 Batch 10 Loss 0.0022\n",
      "Epoch 6 Batch 20 Loss 0.0005\n",
      "Epoch 6 Batch 30 Loss 0.0002\n",
      "Epoch 6 Batch 40 Loss 0.0002\n",
      "Epoch 6 Batch 50 Loss 0.0001\n",
      "Epoch 6 Batch 60 Loss 0.0042\n",
      "Epoch 6 Batch 70 Loss 0.0135\n",
      "Epoch 6 Loss 0.0036\n",
      "Time taken for 1 epoch 65.15646147727966 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0013\n",
      "Epoch 7 Batch 10 Loss 0.0004\n",
      "Epoch 7 Batch 20 Loss 0.0004\n",
      "Epoch 7 Batch 30 Loss 0.0001\n",
      "Epoch 7 Batch 40 Loss 0.0003\n",
      "Epoch 7 Batch 50 Loss 0.0010\n",
      "Epoch 7 Batch 60 Loss 0.0022\n",
      "Epoch 7 Batch 70 Loss 0.0128\n",
      "Epoch 7 Loss 0.0034\n",
      "Time taken for 1 epoch 65.00053000450134 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0054\n",
      "Epoch 8 Batch 10 Loss 0.0011\n",
      "Epoch 8 Batch 20 Loss 0.0010\n",
      "Epoch 8 Batch 30 Loss 0.0002\n",
      "Epoch 8 Batch 40 Loss 0.0001\n",
      "Epoch 8 Batch 50 Loss 0.0001\n",
      "Epoch 8 Batch 60 Loss 0.0010\n",
      "Epoch 8 Batch 70 Loss 0.0137\n",
      "Epoch 8 Loss 0.0023\n",
      "Time taken for 1 epoch 65.15159940719604 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0003\n",
      "Epoch 9 Batch 10 Loss 0.0006\n",
      "Epoch 9 Batch 20 Loss 0.0002\n",
      "Epoch 9 Batch 30 Loss 0.0001\n",
      "Epoch 9 Batch 40 Loss 0.0001\n",
      "Epoch 9 Batch 50 Loss 0.0000\n",
      "Epoch 9 Batch 60 Loss 0.0011\n",
      "Epoch 9 Batch 70 Loss 0.0136\n",
      "Epoch 9 Loss 0.0015\n",
      "Time taken for 1 epoch 64.52530312538147 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0003\n",
      "Epoch 10 Batch 10 Loss 0.0002\n",
      "Epoch 10 Batch 20 Loss 0.0001\n",
      "Epoch 10 Batch 30 Loss 0.0021\n",
      "Epoch 10 Batch 40 Loss 0.0000\n",
      "Epoch 10 Batch 50 Loss 0.0001\n",
      "Epoch 10 Batch 60 Loss 0.0102\n",
      "Epoch 10 Batch 70 Loss 0.0130\n",
      "Epoch 10 Loss 0.0019\n",
      "Time taken for 1 epoch 66.29974436759949 sec\n",
      "\n",
      "Evaluation:\n",
      "accuracy:0.9910394265232975\n",
      "\n",
      "=========50d_lower_processed_data.pkl=========\n",
      "Training:\n",
      "Epoch 1 Batch 0 Loss 0.1327\n",
      "Epoch 1 Batch 10 Loss 0.0355\n",
      "Epoch 1 Batch 20 Loss 0.0095\n",
      "Epoch 1 Batch 30 Loss 0.0232\n",
      "Epoch 1 Batch 40 Loss 0.0162\n",
      "Epoch 1 Batch 50 Loss 0.0128\n",
      "Epoch 1 Batch 60 Loss 0.0569\n",
      "Epoch 1 Batch 70 Loss 0.0273\n",
      "Epoch 1 Loss 0.0522\n",
      "Time taken for 1 epoch 68.0709855556488 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.0514\n",
      "Epoch 2 Batch 10 Loss 0.0194\n",
      "Epoch 2 Batch 20 Loss 0.0127\n",
      "Epoch 2 Batch 30 Loss 0.0097\n",
      "Epoch 2 Batch 40 Loss 0.0081\n",
      "Epoch 2 Batch 50 Loss 0.0024\n",
      "Epoch 2 Batch 60 Loss 0.0259\n",
      "Epoch 2 Batch 70 Loss 0.0134\n",
      "Epoch 2 Loss 0.0192\n",
      "Time taken for 1 epoch 69.3766713142395 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0134\n",
      "Epoch 3 Batch 10 Loss 0.0182\n",
      "Epoch 3 Batch 20 Loss 0.0050\n",
      "Epoch 3 Batch 30 Loss 0.0056\n",
      "Epoch 3 Batch 40 Loss 0.0025\n",
      "Epoch 3 Batch 50 Loss 0.0052\n",
      "Epoch 3 Batch 60 Loss 0.0263\n",
      "Epoch 3 Batch 70 Loss 0.0162\n",
      "Epoch 3 Loss 0.0118\n",
      "Time taken for 1 epoch 67.98592901229858 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0194\n",
      "Epoch 4 Batch 10 Loss 0.0027\n",
      "Epoch 4 Batch 20 Loss 0.0034\n",
      "Epoch 4 Batch 30 Loss 0.0173\n",
      "Epoch 4 Batch 40 Loss 0.0040\n",
      "Epoch 4 Batch 50 Loss 0.0023\n",
      "Epoch 4 Batch 60 Loss 0.0162\n",
      "Epoch 4 Batch 70 Loss 0.0201\n",
      "Epoch 4 Loss 0.0089\n",
      "Time taken for 1 epoch 68.03880000114441 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0179\n",
      "Epoch 5 Batch 10 Loss 0.0029\n",
      "Epoch 5 Batch 20 Loss 0.0029\n",
      "Epoch 5 Batch 30 Loss 0.0022\n",
      "Epoch 5 Batch 40 Loss 0.0006\n",
      "Epoch 5 Batch 50 Loss 0.0007\n",
      "Epoch 5 Batch 60 Loss 0.0151\n",
      "Epoch 5 Batch 70 Loss 0.0123\n",
      "Epoch 5 Loss 0.0063\n",
      "Time taken for 1 epoch 68.46694707870483 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0090\n",
      "Epoch 6 Batch 10 Loss 0.0007\n",
      "Epoch 6 Batch 20 Loss 0.0005\n",
      "Epoch 6 Batch 30 Loss 0.0034\n",
      "Epoch 6 Batch 40 Loss 0.0003\n",
      "Epoch 6 Batch 50 Loss 0.0013\n",
      "Epoch 6 Batch 60 Loss 0.0100\n",
      "Epoch 6 Batch 70 Loss 0.0115\n",
      "Epoch 6 Loss 0.0046\n",
      "Time taken for 1 epoch 68.5977725982666 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0054\n",
      "Epoch 7 Batch 10 Loss 0.0031\n",
      "Epoch 7 Batch 20 Loss 0.0025\n",
      "Epoch 7 Batch 30 Loss 0.0055\n",
      "Epoch 7 Batch 40 Loss 0.0006\n",
      "Epoch 7 Batch 50 Loss 0.0005\n",
      "Epoch 7 Batch 60 Loss 0.0032\n",
      "Epoch 7 Batch 70 Loss 0.0128\n",
      "Epoch 7 Loss 0.0036\n",
      "Time taken for 1 epoch 67.62966108322144 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0015\n",
      "Epoch 8 Batch 10 Loss 0.0021\n",
      "Epoch 8 Batch 20 Loss 0.0008\n",
      "Epoch 8 Batch 30 Loss 0.0006\n",
      "Epoch 8 Batch 40 Loss 0.0021\n",
      "Epoch 8 Batch 50 Loss 0.0002\n",
      "Epoch 8 Batch 60 Loss 0.0012\n",
      "Epoch 8 Batch 70 Loss 0.0107\n",
      "Epoch 8 Loss 0.0035\n",
      "Time taken for 1 epoch 67.36195468902588 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0058\n",
      "Epoch 9 Batch 10 Loss 0.0002\n",
      "Epoch 9 Batch 20 Loss 0.0002\n",
      "Epoch 9 Batch 30 Loss 0.0008\n",
      "Epoch 9 Batch 40 Loss 0.0011\n",
      "Epoch 9 Batch 50 Loss 0.0013\n",
      "Epoch 9 Batch 60 Loss 0.0041\n",
      "Epoch 9 Batch 70 Loss 0.0097\n",
      "Epoch 9 Loss 0.0035\n",
      "Time taken for 1 epoch 68.52912092208862 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0011\n",
      "Epoch 10 Batch 10 Loss 0.0001\n",
      "Epoch 10 Batch 20 Loss 0.0004\n",
      "Epoch 10 Batch 30 Loss 0.0001\n",
      "Epoch 10 Batch 40 Loss 0.0001\n",
      "Epoch 10 Batch 50 Loss 0.0022\n",
      "Epoch 10 Batch 60 Loss 0.0082\n",
      "Epoch 10 Batch 70 Loss 0.0032\n",
      "Epoch 10 Loss 0.0024\n",
      "Time taken for 1 epoch 67.7908148765564 sec\n",
      "\n",
      "Evaluation:\n",
      "accuracy:0.9910394265232975\n",
      "\n",
      "=========100d_processed_data.pkl=========\n",
      "Training:\n",
      "Epoch 1 Batch 0 Loss 0.1241\n",
      "Epoch 1 Batch 10 Loss 0.0332\n",
      "Epoch 1 Batch 20 Loss 0.0118\n",
      "Epoch 1 Batch 30 Loss 0.0305\n",
      "Epoch 1 Batch 40 Loss 0.0242\n",
      "Epoch 1 Batch 50 Loss 0.0116\n",
      "Epoch 1 Batch 60 Loss 0.0402\n",
      "Epoch 1 Batch 70 Loss 0.0302\n",
      "Epoch 1 Loss 0.0469\n",
      "Time taken for 1 epoch 75.92388343811035 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.0194\n",
      "Epoch 2 Batch 10 Loss 0.0242\n",
      "Epoch 2 Batch 20 Loss 0.0044\n",
      "Epoch 2 Batch 30 Loss 0.0083\n",
      "Epoch 2 Batch 40 Loss 0.0039\n",
      "Epoch 2 Batch 50 Loss 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 60 Loss 0.0345\n",
      "Epoch 2 Batch 70 Loss 0.0146\n",
      "Epoch 2 Loss 0.0170\n",
      "Time taken for 1 epoch 75.92698049545288 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0230\n",
      "Epoch 3 Batch 10 Loss 0.0160\n",
      "Epoch 3 Batch 20 Loss 0.0016\n",
      "Epoch 3 Batch 30 Loss 0.0017\n",
      "Epoch 3 Batch 40 Loss 0.0014\n",
      "Epoch 3 Batch 50 Loss 0.0012\n",
      "Epoch 3 Batch 60 Loss 0.0072\n",
      "Epoch 3 Batch 70 Loss 0.0067\n",
      "Epoch 3 Loss 0.0086\n",
      "Time taken for 1 epoch 74.88453555107117 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0051\n",
      "Epoch 4 Batch 10 Loss 0.0169\n",
      "Epoch 4 Batch 20 Loss 0.0034\n",
      "Epoch 4 Batch 30 Loss 0.0033\n",
      "Epoch 4 Batch 40 Loss 0.0011\n",
      "Epoch 4 Batch 50 Loss 0.0004\n",
      "Epoch 4 Batch 60 Loss 0.0085\n",
      "Epoch 4 Batch 70 Loss 0.0048\n",
      "Epoch 4 Loss 0.0061\n",
      "Time taken for 1 epoch 75.92317509651184 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0010\n",
      "Epoch 5 Batch 10 Loss 0.0131\n",
      "Epoch 5 Batch 20 Loss 0.0006\n",
      "Epoch 5 Batch 30 Loss 0.0007\n",
      "Epoch 5 Batch 40 Loss 0.0005\n",
      "Epoch 5 Batch 50 Loss 0.0029\n",
      "Epoch 5 Batch 60 Loss 0.0060\n",
      "Epoch 5 Batch 70 Loss 0.0018\n",
      "Epoch 5 Loss 0.0043\n",
      "Time taken for 1 epoch 74.65785026550293 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0004\n",
      "Epoch 6 Batch 10 Loss 0.0128\n",
      "Epoch 6 Batch 20 Loss 0.0001\n",
      "Epoch 6 Batch 30 Loss 0.0012\n",
      "Epoch 6 Batch 40 Loss 0.0004\n",
      "Epoch 6 Batch 50 Loss 0.0004\n",
      "Epoch 6 Batch 60 Loss 0.0014\n",
      "Epoch 6 Batch 70 Loss 0.0053\n",
      "Epoch 6 Loss 0.0028\n",
      "Time taken for 1 epoch 75.90411925315857 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0004\n",
      "Epoch 7 Batch 10 Loss 0.0017\n",
      "Epoch 7 Batch 20 Loss 0.0001\n",
      "Epoch 7 Batch 30 Loss 0.0004\n",
      "Epoch 7 Batch 40 Loss 0.0004\n",
      "Epoch 7 Batch 50 Loss 0.0003\n",
      "Epoch 7 Batch 60 Loss 0.0040\n",
      "Epoch 7 Batch 70 Loss 0.0021\n",
      "Epoch 7 Loss 0.0018\n",
      "Time taken for 1 epoch 73.95894145965576 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0059\n",
      "Epoch 8 Batch 10 Loss 0.0001\n",
      "Epoch 8 Batch 20 Loss 0.0000\n",
      "Epoch 8 Batch 30 Loss 0.0005\n",
      "Epoch 8 Batch 40 Loss 0.0003\n",
      "Epoch 8 Batch 50 Loss 0.0003\n",
      "Epoch 8 Batch 60 Loss 0.0010\n",
      "Epoch 8 Batch 70 Loss 0.0015\n",
      "Epoch 8 Loss 0.0017\n",
      "Time taken for 1 epoch 75.55644202232361 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0001\n",
      "Epoch 9 Batch 10 Loss 0.0000\n",
      "Epoch 9 Batch 20 Loss 0.0000\n",
      "Epoch 9 Batch 30 Loss 0.0003\n",
      "Epoch 9 Batch 40 Loss 0.0005\n",
      "Epoch 9 Batch 50 Loss 0.0003\n",
      "Epoch 9 Batch 60 Loss 0.0005\n",
      "Epoch 9 Batch 70 Loss 0.0014\n",
      "Epoch 9 Loss 0.0011\n",
      "Time taken for 1 epoch 75.57972383499146 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0001\n",
      "Epoch 10 Batch 10 Loss 0.0000\n",
      "Epoch 10 Batch 20 Loss 0.0000\n",
      "Epoch 10 Batch 30 Loss 0.0003\n",
      "Epoch 10 Batch 40 Loss 0.0004\n",
      "Epoch 10 Batch 50 Loss 0.0003\n",
      "Epoch 10 Batch 60 Loss 0.0005\n",
      "Epoch 10 Batch 70 Loss 0.0015\n",
      "Epoch 10 Loss 0.0010\n",
      "Time taken for 1 epoch 73.57609939575195 sec\n",
      "\n",
      "Evaluation:\n",
      "accuracy:0.9874551971326165\n",
      "\n",
      "=========300d_lower_processed_data.pkl=========\n",
      "Training:\n",
      "Epoch 1 Batch 0 Loss 0.1279\n",
      "Epoch 1 Batch 10 Loss 0.0397\n",
      "Epoch 1 Batch 20 Loss 0.0084\n",
      "Epoch 1 Batch 30 Loss 0.0087\n",
      "Epoch 1 Batch 40 Loss 0.0090\n",
      "Epoch 1 Batch 50 Loss 0.0016\n",
      "Epoch 1 Batch 60 Loss 0.0193\n",
      "Epoch 1 Batch 70 Loss 0.0143\n",
      "Epoch 1 Loss 0.0223\n",
      "Time taken for 1 epoch 101.85439157485962 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.0072\n",
      "Epoch 2 Batch 10 Loss 0.0066\n",
      "Epoch 2 Batch 20 Loss 0.0020\n",
      "Epoch 2 Batch 30 Loss 0.0041\n",
      "Epoch 2 Batch 40 Loss 0.0004\n",
      "Epoch 2 Batch 50 Loss 0.0033\n",
      "Epoch 2 Batch 60 Loss 0.0093\n",
      "Epoch 2 Batch 70 Loss 0.0053\n",
      "Epoch 2 Loss 0.0051\n",
      "Time taken for 1 epoch 101.68545866012573 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0007\n",
      "Epoch 3 Batch 10 Loss 0.0009\n",
      "Epoch 3 Batch 20 Loss 0.0037\n",
      "Epoch 3 Batch 30 Loss 0.0001\n",
      "Epoch 3 Batch 40 Loss 0.0001\n",
      "Epoch 3 Batch 50 Loss 0.0025\n",
      "Epoch 3 Batch 60 Loss 0.0045\n",
      "Epoch 3 Batch 70 Loss 0.0028\n",
      "Epoch 3 Loss 0.0030\n",
      "Time taken for 1 epoch 99.76950025558472 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0004\n",
      "Epoch 4 Batch 10 Loss 0.0017\n",
      "Epoch 4 Batch 20 Loss 0.0016\n",
      "Epoch 4 Batch 30 Loss 0.0004\n",
      "Epoch 4 Batch 40 Loss 0.0000\n",
      "Epoch 4 Batch 50 Loss 0.0002\n",
      "Epoch 4 Batch 60 Loss 0.0020\n",
      "Epoch 4 Batch 70 Loss 0.0004\n",
      "Epoch 4 Loss 0.0019\n",
      "Time taken for 1 epoch 99.43146896362305 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0161\n",
      "Epoch 5 Batch 10 Loss 0.0010\n",
      "Epoch 5 Batch 20 Loss 0.0015\n",
      "Epoch 5 Batch 30 Loss 0.0005\n",
      "Epoch 5 Batch 40 Loss 0.0005\n",
      "Epoch 5 Batch 50 Loss 0.0003\n",
      "Epoch 5 Batch 60 Loss 0.0009\n",
      "Epoch 5 Batch 70 Loss 0.0005\n",
      "Epoch 5 Loss 0.0033\n",
      "Time taken for 1 epoch 101.27474904060364 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0001\n",
      "Epoch 6 Batch 10 Loss 0.0002\n",
      "Epoch 6 Batch 20 Loss 0.0001\n",
      "Epoch 6 Batch 30 Loss 0.0001\n",
      "Epoch 6 Batch 40 Loss 0.0000\n",
      "Epoch 6 Batch 50 Loss 0.0000\n",
      "Epoch 6 Batch 60 Loss 0.0002\n",
      "Epoch 6 Batch 70 Loss 0.0006\n",
      "Epoch 6 Loss 0.0009\n",
      "Time taken for 1 epoch 101.71053719520569 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0001\n",
      "Epoch 7 Batch 10 Loss 0.0002\n",
      "Epoch 7 Batch 20 Loss 0.0001\n",
      "Epoch 7 Batch 30 Loss 0.0002\n",
      "Epoch 7 Batch 40 Loss 0.0000\n",
      "Epoch 7 Batch 50 Loss 0.0000\n",
      "Epoch 7 Batch 60 Loss 0.0001\n",
      "Epoch 7 Batch 70 Loss 0.0005\n",
      "Epoch 7 Loss 0.0007\n",
      "Time taken for 1 epoch 101.90239906311035 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0001\n",
      "Epoch 8 Batch 10 Loss 0.0002\n",
      "Epoch 8 Batch 20 Loss 0.0001\n",
      "Epoch 8 Batch 30 Loss 0.0000\n",
      "Epoch 8 Batch 40 Loss 0.0000\n",
      "Epoch 8 Batch 50 Loss 0.0000\n",
      "Epoch 8 Batch 60 Loss 0.0001\n",
      "Epoch 8 Batch 70 Loss 0.0006\n",
      "Epoch 8 Loss 0.0005\n",
      "Time taken for 1 epoch 101.6253457069397 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0001\n",
      "Epoch 9 Batch 10 Loss 0.0001\n",
      "Epoch 9 Batch 20 Loss 0.0001\n",
      "Epoch 9 Batch 30 Loss 0.0000\n",
      "Epoch 9 Batch 40 Loss 0.0000\n",
      "Epoch 9 Batch 50 Loss 0.0000\n",
      "Epoch 9 Batch 60 Loss 0.0001\n",
      "Epoch 9 Batch 70 Loss 0.0007\n",
      "Epoch 9 Loss 0.0005\n",
      "Time taken for 1 epoch 101.3009922504425 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0001\n",
      "Epoch 10 Batch 10 Loss 0.0001\n",
      "Epoch 10 Batch 20 Loss 0.0001\n",
      "Epoch 10 Batch 30 Loss 0.0000\n",
      "Epoch 10 Batch 40 Loss 0.0000\n",
      "Epoch 10 Batch 50 Loss 0.0000\n",
      "Epoch 10 Batch 60 Loss 0.0001\n",
      "Epoch 10 Batch 70 Loss 0.0007\n",
      "Epoch 10 Loss 0.0004\n",
      "Time taken for 1 epoch 101.90381193161011 sec\n",
      "\n",
      "Evaluation:\n",
      "accuracy:1.0\n",
      "\n",
      "=========50d_processed_data.pkl=========\n",
      "Training:\n",
      "Epoch 1 Batch 0 Loss 0.1373\n",
      "Epoch 1 Batch 10 Loss 0.0378\n",
      "Epoch 1 Batch 20 Loss 0.0120\n",
      "Epoch 1 Batch 30 Loss 0.0362\n",
      "Epoch 1 Batch 40 Loss 0.0308\n",
      "Epoch 1 Batch 50 Loss 0.0059\n",
      "Epoch 1 Batch 60 Loss 0.0243\n",
      "Epoch 1 Batch 70 Loss 0.0193\n",
      "Epoch 1 Loss 0.0478\n",
      "Time taken for 1 epoch 69.07977223396301 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.0275\n",
      "Epoch 2 Batch 10 Loss 0.0217\n",
      "Epoch 2 Batch 20 Loss 0.0074\n",
      "Epoch 2 Batch 30 Loss 0.0065\n",
      "Epoch 2 Batch 40 Loss 0.0034\n",
      "Epoch 2 Batch 50 Loss 0.0018\n",
      "Epoch 2 Batch 60 Loss 0.0277\n",
      "Epoch 2 Batch 70 Loss 0.0240\n",
      "Epoch 2 Loss 0.0159\n",
      "Time taken for 1 epoch 67.6665608882904 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0297\n",
      "Epoch 3 Batch 10 Loss 0.0130\n",
      "Epoch 3 Batch 20 Loss 0.0041\n",
      "Epoch 3 Batch 30 Loss 0.0035\n",
      "Epoch 3 Batch 40 Loss 0.0018\n",
      "Epoch 3 Batch 50 Loss 0.0015\n",
      "Epoch 3 Batch 60 Loss 0.0099\n",
      "Epoch 3 Batch 70 Loss 0.0087\n",
      "Epoch 3 Loss 0.0090\n",
      "Time taken for 1 epoch 69.47402858734131 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0202\n",
      "Epoch 4 Batch 10 Loss 0.0081\n",
      "Epoch 4 Batch 20 Loss 0.0049\n",
      "Epoch 4 Batch 30 Loss 0.0039\n",
      "Epoch 4 Batch 40 Loss 0.0008\n",
      "Epoch 4 Batch 50 Loss 0.0016\n",
      "Epoch 4 Batch 60 Loss 0.0055\n",
      "Epoch 4 Batch 70 Loss 0.0038\n",
      "Epoch 4 Loss 0.0067\n",
      "Time taken for 1 epoch 68.09133911132812 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0011\n",
      "Epoch 5 Batch 10 Loss 0.0167\n",
      "Epoch 5 Batch 20 Loss 0.0014\n",
      "Epoch 5 Batch 30 Loss 0.0015\n",
      "Epoch 5 Batch 40 Loss 0.0014\n",
      "Epoch 5 Batch 50 Loss 0.0008\n",
      "Epoch 5 Batch 60 Loss 0.0024\n",
      "Epoch 5 Batch 70 Loss 0.0036\n",
      "Epoch 5 Loss 0.0056\n",
      "Time taken for 1 epoch 68.05567765235901 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0006\n",
      "Epoch 6 Batch 10 Loss 0.0099\n",
      "Epoch 6 Batch 20 Loss 0.0010\n",
      "Epoch 6 Batch 30 Loss 0.0010\n",
      "Epoch 6 Batch 40 Loss 0.0005\n",
      "Epoch 6 Batch 50 Loss 0.0016\n",
      "Epoch 6 Batch 60 Loss 0.0023\n",
      "Epoch 6 Batch 70 Loss 0.0019\n",
      "Epoch 6 Loss 0.0046\n",
      "Time taken for 1 epoch 68.85286569595337 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0007\n",
      "Epoch 7 Batch 10 Loss 0.0008\n",
      "Epoch 7 Batch 20 Loss 0.0001\n",
      "Epoch 7 Batch 30 Loss 0.0012\n",
      "Epoch 7 Batch 40 Loss 0.0003\n",
      "Epoch 7 Batch 50 Loss 0.0004\n",
      "Epoch 7 Batch 60 Loss 0.0017\n",
      "Epoch 7 Batch 70 Loss 0.0024\n",
      "Epoch 7 Loss 0.0035\n",
      "Time taken for 1 epoch 68.90833473205566 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0074\n",
      "Epoch 8 Batch 10 Loss 0.0021\n",
      "Epoch 8 Batch 20 Loss 0.0003\n",
      "Epoch 8 Batch 30 Loss 0.0004\n",
      "Epoch 8 Batch 40 Loss 0.0003\n",
      "Epoch 8 Batch 50 Loss 0.0003\n",
      "Epoch 8 Batch 60 Loss 0.0010\n",
      "Epoch 8 Batch 70 Loss 0.0012\n",
      "Epoch 8 Loss 0.0024\n",
      "Time taken for 1 epoch 69.0007586479187 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0001\n",
      "Epoch 9 Batch 10 Loss 0.0001\n",
      "Epoch 9 Batch 20 Loss 0.0002\n",
      "Epoch 9 Batch 30 Loss 0.0003\n",
      "Epoch 9 Batch 40 Loss 0.0003\n",
      "Epoch 9 Batch 50 Loss 0.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 60 Loss 0.0010\n",
      "Epoch 9 Batch 70 Loss 0.0011\n",
      "Epoch 9 Loss 0.0016\n",
      "Time taken for 1 epoch 66.70258903503418 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0001\n",
      "Epoch 10 Batch 10 Loss 0.0001\n",
      "Epoch 10 Batch 20 Loss 0.0000\n",
      "Epoch 10 Batch 30 Loss 0.0002\n",
      "Epoch 10 Batch 40 Loss 0.0003\n",
      "Epoch 10 Batch 50 Loss 0.0003\n",
      "Epoch 10 Batch 60 Loss 0.0006\n",
      "Epoch 10 Batch 70 Loss 0.0012\n",
      "Epoch 10 Loss 0.0013\n",
      "Time taken for 1 epoch 69.93519806861877 sec\n",
      "\n",
      "Evaluation:\n",
      "accuracy:0.982078853046595\n",
      "\n",
      "=========100d_lower_processed_data.pkl=========\n",
      "Training:\n",
      "Epoch 1 Batch 0 Loss 0.1302\n",
      "Epoch 1 Batch 10 Loss 0.0309\n",
      "Epoch 1 Batch 20 Loss 0.0079\n",
      "Epoch 1 Batch 30 Loss 0.0101\n",
      "Epoch 1 Batch 40 Loss 0.0042\n",
      "Epoch 1 Batch 50 Loss 0.0011\n",
      "Epoch 1 Batch 60 Loss 0.0341\n",
      "Epoch 1 Batch 70 Loss 0.0244\n",
      "Epoch 1 Loss 0.0254\n",
      "Time taken for 1 epoch 74.5204119682312 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.0308\n",
      "Epoch 2 Batch 10 Loss 0.0065\n",
      "Epoch 2 Batch 20 Loss 0.0070\n",
      "Epoch 2 Batch 30 Loss 0.0081\n",
      "Epoch 2 Batch 40 Loss 0.0010\n",
      "Epoch 2 Batch 50 Loss 0.0003\n",
      "Epoch 2 Batch 60 Loss 0.0159\n",
      "Epoch 2 Batch 70 Loss 0.0096\n",
      "Epoch 2 Loss 0.0076\n",
      "Time taken for 1 epoch 75.77639389038086 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0128\n",
      "Epoch 3 Batch 10 Loss 0.0021\n",
      "Epoch 3 Batch 20 Loss 0.0068\n",
      "Epoch 3 Batch 30 Loss 0.0023\n",
      "Epoch 3 Batch 40 Loss 0.0002\n",
      "Epoch 3 Batch 50 Loss 0.0001\n",
      "Epoch 3 Batch 60 Loss 0.0058\n",
      "Epoch 3 Batch 70 Loss 0.0038\n",
      "Epoch 3 Loss 0.0037\n",
      "Time taken for 1 epoch 75.08505892753601 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0023\n",
      "Epoch 4 Batch 10 Loss 0.0004\n",
      "Epoch 4 Batch 20 Loss 0.0037\n",
      "Epoch 4 Batch 30 Loss 0.0008\n",
      "Epoch 4 Batch 40 Loss 0.0001\n",
      "Epoch 4 Batch 50 Loss 0.0002\n",
      "Epoch 4 Batch 60 Loss 0.0006\n",
      "Epoch 4 Batch 70 Loss 0.0008\n",
      "Epoch 4 Loss 0.0019\n",
      "Time taken for 1 epoch 75.26038980484009 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0006\n",
      "Epoch 5 Batch 10 Loss 0.0004\n",
      "Epoch 5 Batch 20 Loss 0.0016\n",
      "Epoch 5 Batch 30 Loss 0.0009\n",
      "Epoch 5 Batch 40 Loss 0.0001\n",
      "Epoch 5 Batch 50 Loss 0.0016\n",
      "Epoch 5 Batch 60 Loss 0.0006\n",
      "Epoch 5 Batch 70 Loss 0.0005\n",
      "Epoch 5 Loss 0.0015\n",
      "Time taken for 1 epoch 75.07367944717407 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0003\n",
      "Epoch 6 Batch 10 Loss 0.0040\n",
      "Epoch 6 Batch 20 Loss 0.0002\n",
      "Epoch 6 Batch 30 Loss 0.0002\n",
      "Epoch 6 Batch 40 Loss 0.0024\n",
      "Epoch 6 Batch 50 Loss 0.0003\n",
      "Epoch 6 Batch 60 Loss 0.0004\n",
      "Epoch 6 Batch 70 Loss 0.0006\n",
      "Epoch 6 Loss 0.0012\n",
      "Time taken for 1 epoch 74.38567519187927 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0011\n",
      "Epoch 7 Batch 10 Loss 0.0001\n",
      "Epoch 7 Batch 20 Loss 0.0021\n",
      "Epoch 7 Batch 30 Loss 0.0002\n",
      "Epoch 7 Batch 40 Loss 0.0001\n",
      "Epoch 7 Batch 50 Loss 0.0000\n",
      "Epoch 7 Batch 60 Loss 0.0002\n",
      "Epoch 7 Batch 70 Loss 0.0007\n",
      "Epoch 7 Loss 0.0010\n",
      "Time taken for 1 epoch 75.75968170166016 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0000\n",
      "Epoch 8 Batch 10 Loss 0.0001\n",
      "Epoch 8 Batch 20 Loss 0.0007\n",
      "Epoch 8 Batch 30 Loss 0.0147\n",
      "Epoch 8 Batch 40 Loss 0.0000\n",
      "Epoch 8 Batch 50 Loss 0.0000\n",
      "Epoch 8 Batch 60 Loss 0.0029\n",
      "Epoch 8 Batch 70 Loss 0.0005\n",
      "Epoch 8 Loss 0.0014\n",
      "Time taken for 1 epoch 75.06925678253174 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0002\n",
      "Epoch 9 Batch 10 Loss 0.0000\n",
      "Epoch 9 Batch 20 Loss 0.0001\n",
      "Epoch 9 Batch 30 Loss 0.0001\n",
      "Epoch 9 Batch 40 Loss 0.0000\n",
      "Epoch 9 Batch 50 Loss 0.0000\n",
      "Epoch 9 Batch 60 Loss 0.0000\n",
      "Epoch 9 Batch 70 Loss 0.0004\n",
      "Epoch 9 Loss 0.0003\n",
      "Time taken for 1 epoch 76.01551365852356 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0000\n",
      "Epoch 10 Batch 10 Loss 0.0000\n",
      "Epoch 10 Batch 20 Loss 0.0000\n",
      "Epoch 10 Batch 30 Loss 0.0000\n",
      "Epoch 10 Batch 40 Loss 0.0000\n",
      "Epoch 10 Batch 50 Loss 0.0000\n",
      "Epoch 10 Batch 60 Loss 0.0000\n",
      "Epoch 10 Batch 70 Loss 0.0005\n",
      "Epoch 10 Loss 0.0002\n",
      "Time taken for 1 epoch 75.6806309223175 sec\n",
      "\n",
      "Evaluation:\n",
      "accuracy:0.989247311827957\n",
      "\n",
      "=========300d_processed_data.pkl=========\n",
      "Training:\n",
      "Epoch 1 Batch 0 Loss 0.1311\n",
      "Epoch 1 Batch 10 Loss 0.0314\n",
      "Epoch 1 Batch 20 Loss 0.0058\n",
      "Epoch 1 Batch 30 Loss 0.0178\n",
      "Epoch 1 Batch 40 Loss 0.0040\n",
      "Epoch 1 Batch 50 Loss 0.0030\n",
      "Epoch 1 Batch 60 Loss 0.0263\n",
      "Epoch 1 Batch 70 Loss 0.0115\n",
      "Epoch 1 Loss 0.0287\n",
      "Time taken for 1 epoch 102.15554189682007 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.0222\n",
      "Epoch 2 Batch 10 Loss 0.0052\n",
      "Epoch 2 Batch 20 Loss 0.0024\n",
      "Epoch 2 Batch 30 Loss 0.0016\n",
      "Epoch 2 Batch 40 Loss 0.0002\n",
      "Epoch 2 Batch 50 Loss 0.0007\n",
      "Epoch 2 Batch 60 Loss 0.0067\n",
      "Epoch 2 Batch 70 Loss 0.0072\n",
      "Epoch 2 Loss 0.0054\n",
      "Time taken for 1 epoch 101.40542268753052 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0112\n",
      "Epoch 3 Batch 10 Loss 0.0011\n",
      "Epoch 3 Batch 20 Loss 0.0009\n",
      "Epoch 3 Batch 30 Loss 0.0003\n",
      "Epoch 3 Batch 40 Loss 0.0002\n",
      "Epoch 3 Batch 50 Loss 0.0007\n",
      "Epoch 3 Batch 60 Loss 0.0004\n",
      "Epoch 3 Batch 70 Loss 0.0105\n",
      "Epoch 3 Loss 0.0027\n",
      "Time taken for 1 epoch 101.08080816268921 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0002\n",
      "Epoch 4 Batch 10 Loss 0.0019\n",
      "Epoch 4 Batch 20 Loss 0.0004\n",
      "Epoch 4 Batch 30 Loss 0.0001\n",
      "Epoch 4 Batch 40 Loss 0.0003\n",
      "Epoch 4 Batch 50 Loss 0.0000\n",
      "Epoch 4 Batch 60 Loss 0.0018\n",
      "Epoch 4 Batch 70 Loss 0.0009\n",
      "Epoch 4 Loss 0.0010\n",
      "Time taken for 1 epoch 101.97271919250488 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0001\n",
      "Epoch 5 Batch 10 Loss 0.0001\n",
      "Epoch 5 Batch 20 Loss 0.0003\n",
      "Epoch 5 Batch 30 Loss 0.0001\n",
      "Epoch 5 Batch 40 Loss 0.0001\n",
      "Epoch 5 Batch 50 Loss 0.0000\n",
      "Epoch 5 Batch 60 Loss 0.0001\n",
      "Epoch 5 Batch 70 Loss 0.0008\n",
      "Epoch 5 Loss 0.0006\n",
      "Time taken for 1 epoch 100.77254557609558 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0000\n",
      "Epoch 6 Batch 10 Loss 0.0001\n",
      "Epoch 6 Batch 20 Loss 0.0000\n",
      "Epoch 6 Batch 30 Loss 0.0021\n",
      "Epoch 6 Batch 40 Loss 0.0000\n",
      "Epoch 6 Batch 50 Loss 0.0000\n",
      "Epoch 6 Batch 60 Loss 0.0000\n",
      "Epoch 6 Batch 70 Loss 0.0006\n",
      "Epoch 6 Loss 0.0004\n",
      "Time taken for 1 epoch 99.327312707901 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0001\n",
      "Epoch 7 Batch 10 Loss 0.0001\n",
      "Epoch 7 Batch 20 Loss 0.0001\n",
      "Epoch 7 Batch 30 Loss 0.0000\n",
      "Epoch 7 Batch 40 Loss 0.0000\n",
      "Epoch 7 Batch 50 Loss 0.0000\n",
      "Epoch 7 Batch 60 Loss 0.0000\n",
      "Epoch 7 Batch 70 Loss 0.0006\n",
      "Epoch 7 Loss 0.0003\n",
      "Time taken for 1 epoch 99.82722878456116 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0000\n",
      "Epoch 8 Batch 10 Loss 0.0000\n",
      "Epoch 8 Batch 20 Loss 0.0000\n",
      "Epoch 8 Batch 30 Loss 0.0000\n",
      "Epoch 8 Batch 40 Loss 0.0000\n",
      "Epoch 8 Batch 50 Loss 0.0000\n",
      "Epoch 8 Batch 60 Loss 0.0000\n",
      "Epoch 8 Batch 70 Loss 0.0007\n",
      "Epoch 8 Loss 0.0003\n",
      "Time taken for 1 epoch 100.9431562423706 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0000\n",
      "Epoch 9 Batch 10 Loss 0.0000\n",
      "Epoch 9 Batch 20 Loss 0.0000\n",
      "Epoch 9 Batch 30 Loss 0.0000\n",
      "Epoch 9 Batch 40 Loss 0.0000\n",
      "Epoch 9 Batch 50 Loss 0.0000\n",
      "Epoch 9 Batch 60 Loss 0.0000\n",
      "Epoch 9 Batch 70 Loss 0.0007\n",
      "Epoch 9 Loss 0.0002\n",
      "Time taken for 1 epoch 101.91237807273865 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0001\n",
      "Epoch 10 Batch 10 Loss 0.0000\n",
      "Epoch 10 Batch 20 Loss 0.0000\n",
      "Epoch 10 Batch 30 Loss 0.0000\n",
      "Epoch 10 Batch 40 Loss 0.0000\n",
      "Epoch 10 Batch 50 Loss 0.0000\n",
      "Epoch 10 Batch 60 Loss 0.0000\n",
      "Epoch 10 Batch 70 Loss 0.0007\n",
      "Epoch 10 Loss 0.0001\n",
      "Time taken for 1 epoch 101.09211540222168 sec\n",
      "\n",
      "Evaluation:\n",
      "accuracy:0.9910394265232975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = os.getcwd()+r\"/data/processed\"\n",
    "files_name = []\n",
    "for root,subFolders,files in os.walk(data_path):\n",
    "    files_name += files\n",
    "#proccessed = [\"100d_processed_data.pkl\",\"50d_lower_processed_data.pkl\",\"25d_lower_processed_data.pkl\",\"25d_processed_data.pkl\",\"200d_processed_data.pkl\",\"200d_lower_processed_data.pkl\"]\n",
    "for file in files_name:\n",
    "    #if file in proccessed:\n",
    "    #    continue\n",
    "    print(\"========={}=========\".format(file))\n",
    "    cls = attention(file)\n",
    "    print(\"Training:\")\n",
    "    cls.train(EPOCHS=10)\n",
    "    print(\"Evaluation:\")\n",
    "    result, acc =cls.predict()\n",
    "    print(\"accuracy:{}\".format(acc))\n",
    "    del(cls)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam",
   "language": "python",
   "name": "spam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
